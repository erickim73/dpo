{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "263d2011",
   "metadata": {},
   "source": [
    "**TRAINING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31405e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pygame in /home/erickim/pyro-env-py39/lib/python3.9/site-packages (2.6.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "958946c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import train\n",
    "import time\n",
    "def train_helper(env_name, num_optimize_iters, warm_up_threshold, zero_order, save_interval):\n",
    "    start_time = time.time()\n",
    "    train(env_name, num_optimize_iters, warm_up_threshold, zero_order, save_interval)\n",
    "    print('Training takes {} hours'.format(int(time.time()-start_time)/3600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b740590",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce693328",
   "metadata": {},
   "source": [
    "**SHAPE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8417a505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparams: Rate: 1.000, num traj: 128, step size: 0.01000, lr: 0.00100, batch_size: 32, log_interval:1000\n",
      "\n",
      "\n",
      "Currently at stage 0. Reinforce: False\n",
      "Iter 1000: loss 8.964.\n",
      "Iter 2000: loss 4.607.\n",
      "Iter 3000: loss 1.262.\n",
      "Iter 4000: loss 0.673.\n",
      "Iter 5000: loss 0.514.\n",
      "Iter 6000: loss 0.478.\n",
      "Iter 7000: loss 0.449.\n",
      "Iter 8000: loss 0.464.\n",
      "Iter 9000: loss 0.419.\n",
      "Iter 10000: loss 0.399.\n",
      "\n",
      "\n",
      "Currently at stage 1. Reinforce: False\n",
      "Iter 1000: loss 1.463.\n",
      "Iter 2000: loss 0.982.\n",
      "Iter 3000: loss 0.805.\n",
      "Iter 4000: loss 0.685.\n",
      "Iter 5000: loss 0.576.\n",
      "Iter 6000: loss 0.514.\n",
      "Iter 7000: loss 0.517.\n",
      "Iter 8000: loss 0.525.\n",
      "Iter 9000: loss 0.494.\n",
      "Iter 10000: loss 0.467.\n",
      "\n",
      "\n",
      "Currently at stage 2. Reinforce: False\n",
      "Iter 1000: loss 1.637.\n",
      "Iter 2000: loss 1.188.\n",
      "Iter 3000: loss 0.991.\n",
      "Iter 4000: loss 0.905.\n",
      "Iter 5000: loss 0.826.\n",
      "Iter 6000: loss 0.807.\n",
      "Iter 7000: loss 0.749.\n",
      "Iter 8000: loss 0.697.\n",
      "Iter 9000: loss 0.664.\n",
      "Iter 10000: loss 0.625.\n",
      "Iter 11000: loss 0.593.\n",
      "\n",
      "\n",
      "Currently at stage 3. Reinforce: False\n",
      "Iter 1000: loss 0.954.\n",
      "Iter 2000: loss 0.821.\n",
      "Iter 3000: loss 0.692.\n",
      "Iter 4000: loss 0.646.\n",
      "Iter 5000: loss 0.594.\n",
      "Iter 6000: loss 0.574.\n",
      "Iter 7000: loss 0.541.\n",
      "Iter 8000: loss 0.481.\n",
      "Iter 9000: loss 0.441.\n",
      "Iter 10000: loss 0.436.\n",
      "Iter 11000: loss 0.423.\n",
      "\n",
      "\n",
      "Currently at stage 4. Reinforce: False\n",
      "Iter 1000: loss 0.582.\n",
      "Iter 2000: loss 0.495.\n",
      "Iter 3000: loss 0.486.\n",
      "Iter 4000: loss 0.465.\n",
      "Iter 5000: loss 0.429.\n",
      "Iter 6000: loss 0.420.\n",
      "Iter 7000: loss 0.403.\n",
      "Iter 8000: loss 0.390.\n",
      "Iter 9000: loss 0.366.\n",
      "Iter 10000: loss 0.379.\n",
      "Iter 11000: loss 0.366.\n",
      "Iter 12000: loss 0.345.\n",
      "\n",
      "\n",
      "Currently at stage 5. Reinforce: False\n",
      "Iter 1000: loss 0.809.\n",
      "Iter 2000: loss 0.670.\n",
      "Iter 3000: loss 0.630.\n",
      "Iter 4000: loss 0.630.\n",
      "Iter 5000: loss 0.585.\n",
      "Iter 6000: loss 0.595.\n",
      "Iter 7000: loss 0.551.\n",
      "Iter 8000: loss 0.537.\n",
      "Iter 9000: loss 0.586.\n",
      "Iter 10000: loss 0.505.\n",
      "Iter 11000: loss 0.526.\n",
      "Iter 12000: loss 0.484.\n",
      "\n",
      "\n",
      "Currently at stage 6. Reinforce: False\n",
      "Iter 1000: loss 0.781.\n",
      "Iter 2000: loss 0.713.\n",
      "Iter 3000: loss 0.678.\n",
      "Iter 4000: loss 0.600.\n",
      "Iter 5000: loss 0.594.\n",
      "Iter 6000: loss 0.601.\n",
      "Iter 7000: loss 0.582.\n",
      "Iter 8000: loss 0.507.\n",
      "Iter 9000: loss 0.530.\n",
      "Iter 10000: loss 0.495.\n",
      "Iter 11000: loss 0.476.\n",
      "Iter 12000: loss 0.500.\n",
      "Iter 13000: loss 0.460.\n",
      "\n",
      "\n",
      "Currently at stage 7. Reinforce: False\n",
      "Iter 1000: loss 0.595.\n",
      "Iter 2000: loss 0.601.\n",
      "Iter 3000: loss 0.468.\n",
      "Iter 4000: loss 0.509.\n",
      "Iter 5000: loss 0.471.\n",
      "Iter 6000: loss 0.461.\n",
      "Iter 7000: loss 0.450.\n",
      "Iter 8000: loss 0.462.\n",
      "Iter 9000: loss 0.452.\n",
      "Iter 10000: loss 0.442.\n",
      "Iter 11000: loss 0.394.\n",
      "Iter 12000: loss 0.437.\n",
      "Iter 13000: loss 0.463.\n",
      "Iter 14000: loss 0.404.\n",
      "\n",
      "\n",
      "Currently at stage 8. Reinforce: False\n",
      "Iter 1000: loss 0.593.\n",
      "Iter 2000: loss 0.510.\n",
      "Iter 3000: loss 0.519.\n",
      "Iter 4000: loss 0.499.\n",
      "Iter 5000: loss 0.465.\n",
      "Iter 6000: loss 0.481.\n",
      "Iter 7000: loss 0.455.\n",
      "Iter 8000: loss 0.445.\n",
      "Iter 9000: loss 0.424.\n",
      "Iter 10000: loss 0.427.\n",
      "Iter 11000: loss 0.405.\n",
      "Iter 12000: loss 0.372.\n",
      "Iter 13000: loss 0.413.\n",
      "Iter 14000: loss 0.403.\n",
      "\n",
      "\n",
      "Currently at stage 9. Reinforce: False\n",
      "Iter 1000: loss 0.510.\n",
      "Iter 2000: loss 0.430.\n",
      "Iter 3000: loss 0.396.\n",
      "Iter 4000: loss 0.452.\n",
      "Iter 5000: loss 0.381.\n",
      "Iter 6000: loss 0.395.\n",
      "Iter 7000: loss 0.402.\n",
      "Iter 8000: loss 0.386.\n",
      "Iter 9000: loss 0.372.\n",
      "Iter 10000: loss 0.405.\n",
      "Iter 11000: loss 0.370.\n",
      "Iter 12000: loss 0.348.\n",
      "Iter 13000: loss 0.362.\n",
      "Iter 14000: loss 0.346.\n",
      "Iter 15000: loss 0.365.\n",
      "\n",
      "\n",
      "Currently at stage 10. Reinforce: False\n",
      "Iter 1000: loss 0.533.\n",
      "Iter 2000: loss 0.477.\n",
      "Iter 3000: loss 0.501.\n",
      "Iter 4000: loss 0.472.\n",
      "Iter 5000: loss 0.406.\n",
      "Iter 6000: loss 0.474.\n",
      "Iter 7000: loss 0.426.\n",
      "Iter 8000: loss 0.399.\n",
      "Iter 9000: loss 0.431.\n",
      "Iter 10000: loss 0.360.\n",
      "Iter 11000: loss 0.363.\n",
      "Iter 12000: loss 0.404.\n",
      "Iter 13000: loss 0.409.\n",
      "Iter 14000: loss 0.375.\n",
      "Iter 15000: loss 0.386.\n",
      "Iter 16000: loss 0.320.\n",
      "\n",
      "\n",
      "Currently at stage 11. Reinforce: False\n",
      "Iter 1000: loss 0.425.\n",
      "Iter 2000: loss 0.378.\n",
      "Iter 3000: loss 0.463.\n",
      "Iter 4000: loss 0.410.\n",
      "Iter 5000: loss 0.376.\n",
      "Iter 6000: loss 0.409.\n",
      "Iter 7000: loss 0.381.\n",
      "Iter 8000: loss 0.373.\n",
      "Iter 9000: loss 0.350.\n",
      "Iter 10000: loss 0.331.\n",
      "Iter 11000: loss 0.336.\n",
      "Iter 12000: loss 0.345.\n",
      "Iter 13000: loss 0.334.\n",
      "Iter 14000: loss 0.334.\n",
      "Iter 15000: loss 0.331.\n",
      "Iter 16000: loss 0.337.\n",
      "Iter 17000: loss 0.333.\n",
      "\n",
      "\n",
      "Currently at stage 12. Reinforce: False\n",
      "Iter 1000: loss 0.466.\n",
      "Iter 2000: loss 0.443.\n",
      "Iter 3000: loss 0.457.\n",
      "Iter 4000: loss 0.432.\n",
      "Iter 5000: loss 0.547.\n",
      "Iter 6000: loss 0.417.\n",
      "Iter 7000: loss 0.437.\n",
      "Iter 8000: loss 0.446.\n",
      "Iter 9000: loss 0.380.\n",
      "Iter 10000: loss 0.371.\n",
      "Iter 11000: loss 0.389.\n",
      "Iter 12000: loss 0.372.\n",
      "Iter 13000: loss 0.434.\n",
      "Iter 14000: loss 0.404.\n",
      "Iter 15000: loss 0.406.\n",
      "Iter 16000: loss 0.407.\n",
      "Iter 17000: loss 0.370.\n",
      "\n",
      "\n",
      "Currently at stage 13. Reinforce: False\n",
      "Iter 1000: loss 0.481.\n",
      "Iter 2000: loss 0.480.\n",
      "Iter 3000: loss 0.407.\n",
      "Iter 4000: loss 0.377.\n",
      "Iter 5000: loss 0.418.\n",
      "Iter 6000: loss 0.396.\n",
      "Iter 7000: loss 0.359.\n",
      "Iter 8000: loss 0.424.\n",
      "Iter 9000: loss 0.392.\n",
      "Iter 10000: loss 0.412.\n",
      "Iter 11000: loss 0.391.\n",
      "Iter 12000: loss 0.373.\n",
      "Iter 13000: loss 0.354.\n",
      "Iter 14000: loss 0.363.\n",
      "Iter 15000: loss 0.392.\n",
      "Iter 16000: loss 0.380.\n",
      "Iter 17000: loss 0.409.\n",
      "Iter 18000: loss 0.382.\n",
      "\n",
      "\n",
      "Currently at stage 14. Reinforce: False\n",
      "Iter 1000: loss 0.374.\n",
      "Iter 2000: loss 0.326.\n",
      "Iter 3000: loss 0.361.\n",
      "Iter 4000: loss 0.323.\n",
      "Iter 5000: loss 0.371.\n",
      "Iter 6000: loss 0.362.\n",
      "Iter 7000: loss 0.366.\n",
      "Iter 8000: loss 0.358.\n",
      "Iter 9000: loss 0.338.\n",
      "Iter 10000: loss 0.324.\n",
      "Iter 11000: loss 0.391.\n",
      "Iter 12000: loss 0.281.\n",
      "Iter 13000: loss 0.331.\n",
      "Iter 14000: loss 0.335.\n",
      "Iter 15000: loss 0.357.\n",
      "Iter 16000: loss 0.317.\n",
      "Iter 17000: loss 0.356.\n",
      "Iter 18000: loss 0.319.\n",
      "Iter 19000: loss 0.350.\n",
      "\n",
      "\n",
      "Currently at stage 15. Reinforce: True\n",
      "Iter 1000: loss 0.368.\n",
      "Iter 2000: loss 0.318.\n",
      "Iter 3000: loss 0.359.\n",
      "Iter 4000: loss 0.355.\n",
      "Iter 5000: loss 0.361.\n",
      "Iter 6000: loss 0.310.\n",
      "Iter 7000: loss 0.372.\n",
      "Iter 8000: loss 0.351.\n",
      "Iter 9000: loss 0.365.\n",
      "Iter 10000: loss 0.326.\n",
      "Iter 11000: loss 0.290.\n",
      "Iter 12000: loss 0.359.\n",
      "Iter 13000: loss 0.341.\n",
      "Iter 14000: loss 0.331.\n",
      "Iter 15000: loss 0.334.\n",
      "Iter 16000: loss 0.337.\n",
      "Iter 17000: loss 0.346.\n",
      "Iter 18000: loss 0.328.\n",
      "Iter 19000: loss 0.344.\n",
      "Iter 20000: loss 0.322.\n",
      "\n",
      "\n",
      "Currently at stage 16. Reinforce: True\n",
      "Iter 1000: loss 0.330.\n",
      "Iter 2000: loss 0.351.\n",
      "Iter 3000: loss 0.299.\n",
      "Iter 4000: loss 0.294.\n",
      "Iter 5000: loss 0.373.\n",
      "Iter 6000: loss 0.287.\n",
      "Iter 7000: loss 0.336.\n",
      "Iter 8000: loss 0.327.\n",
      "Iter 9000: loss 0.399.\n",
      "Iter 10000: loss 0.319.\n",
      "Iter 11000: loss 0.300.\n",
      "Iter 12000: loss 0.349.\n",
      "Iter 13000: loss 0.334.\n",
      "Iter 14000: loss 0.335.\n",
      "Iter 15000: loss 0.291.\n",
      "Iter 16000: loss 0.338.\n",
      "Iter 17000: loss 0.299.\n",
      "Iter 18000: loss 0.338.\n",
      "Iter 19000: loss 0.305.\n",
      "Iter 20000: loss 0.330.\n",
      "Iter 21000: loss 0.319.\n",
      "\n",
      "\n",
      "Currently at stage 17. Reinforce: True\n",
      "Iter 1000: loss 0.347.\n",
      "Iter 2000: loss 0.337.\n",
      "Iter 3000: loss 0.309.\n",
      "Iter 4000: loss 0.299.\n",
      "Iter 5000: loss 0.324.\n",
      "Iter 6000: loss 0.321.\n",
      "Iter 7000: loss 0.309.\n",
      "Iter 8000: loss 0.310.\n",
      "Iter 9000: loss 0.299.\n",
      "Iter 10000: loss 0.300.\n",
      "Iter 11000: loss 0.292.\n",
      "Iter 12000: loss 0.289.\n",
      "Iter 13000: loss 0.323.\n",
      "Iter 14000: loss 0.283.\n",
      "Iter 15000: loss 0.281.\n",
      "Iter 16000: loss 0.288.\n",
      "Iter 17000: loss 0.308.\n",
      "Iter 18000: loss 0.296.\n",
      "Iter 19000: loss 0.289.\n",
      "Iter 20000: loss 0.300.\n",
      "Iter 21000: loss 0.277.\n",
      "Iter 22000: loss 0.267.\n",
      "\n",
      "\n",
      "Currently at stage 18. Reinforce: True\n",
      "Iter 1000: loss 0.298.\n",
      "Iter 2000: loss 0.286.\n",
      "Iter 3000: loss 0.308.\n",
      "Iter 4000: loss 0.263.\n",
      "Iter 5000: loss 0.283.\n",
      "Iter 6000: loss 0.257.\n",
      "Iter 7000: loss 0.276.\n",
      "Iter 8000: loss 0.289.\n",
      "Iter 9000: loss 0.285.\n",
      "Iter 10000: loss 0.274.\n",
      "Iter 11000: loss 0.268.\n",
      "Iter 12000: loss 0.280.\n",
      "Iter 13000: loss 0.260.\n",
      "Iter 14000: loss 0.284.\n",
      "Iter 15000: loss 0.283.\n",
      "Iter 16000: loss 0.262.\n",
      "Iter 17000: loss 0.303.\n",
      "Iter 18000: loss 0.246.\n",
      "Iter 19000: loss 0.255.\n",
      "Iter 20000: loss 0.271.\n",
      "Iter 21000: loss 0.241.\n",
      "Iter 22000: loss 0.232.\n",
      "Iter 23000: loss 0.267.\n",
      "Iter 24000: loss 0.242.\n",
      "\n",
      "\n",
      "Currently at stage 19. Reinforce: True\n",
      "Iter 1000: loss 0.263.\n",
      "Iter 2000: loss 0.307.\n",
      "Iter 3000: loss 0.247.\n",
      "Iter 4000: loss 0.271.\n",
      "Iter 5000: loss 0.266.\n",
      "Iter 6000: loss 0.256.\n",
      "Iter 7000: loss 0.243.\n",
      "Iter 8000: loss 0.302.\n",
      "Iter 9000: loss 0.239.\n",
      "Iter 10000: loss 0.247.\n",
      "Iter 11000: loss 0.253.\n",
      "Iter 12000: loss 0.257.\n",
      "Iter 13000: loss 0.271.\n",
      "Iter 14000: loss 0.226.\n",
      "Iter 15000: loss 0.280.\n",
      "Iter 16000: loss 0.263.\n",
      "Iter 17000: loss 0.273.\n",
      "Iter 18000: loss 0.238.\n",
      "Iter 19000: loss 0.250.\n",
      "Iter 20000: loss 0.251.\n",
      "Iter 21000: loss 0.244.\n",
      "Iter 22000: loss 0.274.\n",
      "Iter 23000: loss 0.243.\n",
      "Iter 24000: loss 0.231.\n",
      "Iter 25000: loss 0.247.\n",
      "\n",
      "\n",
      "Currently at stage 20. Reinforce: True\n",
      "Iter 1000: loss 0.242.\n",
      "Iter 2000: loss 0.278.\n",
      "Iter 3000: loss 0.255.\n",
      "Iter 4000: loss 0.249.\n",
      "Iter 5000: loss 0.266.\n",
      "Iter 6000: loss 0.239.\n",
      "Iter 7000: loss 0.270.\n",
      "Iter 8000: loss 0.203.\n",
      "Iter 9000: loss 0.245.\n",
      "Iter 10000: loss 0.251.\n",
      "Iter 11000: loss 0.224.\n",
      "Iter 12000: loss 0.240.\n",
      "Iter 13000: loss 0.236.\n",
      "Iter 14000: loss 0.268.\n",
      "Iter 15000: loss 0.235.\n",
      "Iter 16000: loss 0.234.\n",
      "Iter 17000: loss 0.240.\n",
      "Iter 18000: loss 0.246.\n",
      "Iter 19000: loss 0.243.\n",
      "Iter 20000: loss 0.252.\n",
      "Iter 21000: loss 0.247.\n",
      "Iter 22000: loss 0.245.\n",
      "Iter 23000: loss 0.223.\n",
      "Iter 24000: loss 0.239.\n",
      "Iter 25000: loss 0.244.\n",
      "Iter 26000: loss 0.209.\n",
      "\n",
      "Done OCF training.\n",
      "Training takes 0.3761111111111111 hours\n"
     ]
    }
   ],
   "source": [
    "# Shape boundary, zero order.\n",
    "env_name = 'shape_boundary'\n",
    "c = 1.05\n",
    "num_optimize_iters = [int(10000 * (c**i)) for i in range(21)]\n",
    "train_helper(env_name, num_optimize_iters, warm_up_threshold=15, zero_order=True, save_interval=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "379156db",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparams: Rate: 1.000, num traj: 128, step size: 0.01000, lr: 0.00100, batch_size: 32, log_interval:1000\n",
      "\n",
      "\n",
      "Currently at stage 0. Reinforce: False\n",
      "Iter 1000: loss 343.544.\n",
      "Iter 2000: loss 336.376.\n",
      "Iter 3000: loss 304.561.\n",
      "Iter 4000: loss 295.818.\n",
      "Iter 5000: loss 256.814.\n",
      "\n",
      "\n",
      "Currently at stage 1. Reinforce: False\n",
      "Iter 1000: loss 120.544.\n",
      "Iter 2000: loss 110.047.\n",
      "Iter 3000: loss 115.603.\n",
      "Iter 4000: loss 123.423.\n",
      "Iter 5000: loss 113.512.\n",
      "\n",
      "\n",
      "Currently at stage 2. Reinforce: False\n",
      "Iter 1000: loss 88.081.\n",
      "Iter 2000: loss 89.404.\n",
      "Iter 3000: loss 94.114.\n",
      "Iter 4000: loss 75.814.\n",
      "Iter 5000: loss 85.283.\n",
      "\n",
      "\n",
      "Currently at stage 3. Reinforce: False\n",
      "Iter 1000: loss 66.264.\n",
      "Iter 2000: loss 68.986.\n",
      "Iter 3000: loss 70.224.\n",
      "Iter 4000: loss 72.587.\n",
      "Iter 5000: loss 65.799.\n",
      "\n",
      "\n",
      "Currently at stage 4. Reinforce: False\n",
      "Iter 1000: loss 61.497.\n",
      "Iter 2000: loss 53.724.\n",
      "Iter 3000: loss 57.336.\n",
      "Iter 4000: loss 49.900.\n",
      "Iter 5000: loss 55.382.\n",
      "Iter 6000: loss 59.736.\n",
      "\n",
      "\n",
      "Currently at stage 5. Reinforce: False\n",
      "Iter 1000: loss 51.984.\n",
      "Iter 2000: loss 46.068.\n",
      "Iter 3000: loss 46.717.\n",
      "Iter 4000: loss 44.293.\n",
      "Iter 5000: loss 51.766.\n",
      "Iter 6000: loss 45.429.\n",
      "\n",
      "\n",
      "Currently at stage 6. Reinforce: False\n",
      "Iter 1000: loss 302.408.\n",
      "Iter 2000: loss 170.744.\n",
      "Iter 3000: loss 259.477.\n",
      "Iter 4000: loss 253.583.\n",
      "Iter 5000: loss 315.147.\n",
      "Iter 6000: loss 248.974.\n",
      "\n",
      "\n",
      "Currently at stage 7. Reinforce: False\n",
      "Iter 1000: loss 200.885.\n",
      "Iter 2000: loss 248.838.\n",
      "Iter 3000: loss 284.878.\n",
      "Iter 4000: loss 165.494.\n",
      "Iter 5000: loss 261.296.\n",
      "Iter 6000: loss 268.825.\n",
      "Iter 7000: loss 146.153.\n",
      "\n",
      "\n",
      "Currently at stage 8. Reinforce: False\n",
      "Iter 1000: loss 173.599.\n",
      "Iter 2000: loss 203.590.\n",
      "Iter 3000: loss 165.261.\n",
      "Iter 4000: loss 246.935.\n",
      "Iter 5000: loss 183.783.\n",
      "Iter 6000: loss 198.046.\n",
      "Iter 7000: loss 126.818.\n",
      "\n",
      "\n",
      "Currently at stage 9. Reinforce: False\n",
      "Iter 1000: loss 164.733.\n",
      "Iter 2000: loss 220.562.\n",
      "Iter 3000: loss 218.851.\n",
      "Iter 4000: loss 170.089.\n",
      "Iter 5000: loss 173.364.\n",
      "Iter 6000: loss 152.870.\n",
      "Iter 7000: loss 180.143.\n",
      "\n",
      "\n",
      "Currently at stage 10. Reinforce: False\n",
      "Iter 1000: loss 190.980.\n",
      "Iter 2000: loss 147.765.\n",
      "Iter 3000: loss 108.909.\n",
      "Iter 4000: loss 168.565.\n",
      "Iter 5000: loss 108.329.\n",
      "Iter 6000: loss 263.894.\n",
      "Iter 7000: loss 213.561.\n",
      "Iter 8000: loss 156.381.\n",
      "\n",
      "\n",
      "Currently at stage 11. Reinforce: False\n",
      "Iter 1000: loss 191.603.\n",
      "Iter 2000: loss 130.374.\n",
      "Iter 3000: loss 121.073.\n",
      "Iter 4000: loss 185.825.\n",
      "Iter 5000: loss 138.030.\n",
      "Iter 6000: loss 144.587.\n",
      "Iter 7000: loss 149.827.\n",
      "Iter 8000: loss 178.993.\n",
      "\n",
      "\n",
      "Currently at stage 12. Reinforce: False\n",
      "Iter 1000: loss 177.917.\n",
      "Iter 2000: loss 165.098.\n",
      "Iter 3000: loss 143.487.\n",
      "Iter 4000: loss 108.077.\n",
      "Iter 5000: loss 160.245.\n",
      "Iter 6000: loss 235.055.\n",
      "Iter 7000: loss 120.197.\n",
      "Iter 8000: loss 215.577.\n",
      "\n",
      "\n",
      "Currently at stage 13. Reinforce: False\n",
      "Iter 1000: loss 85.341.\n",
      "Iter 2000: loss 130.402.\n",
      "Iter 3000: loss 140.041.\n",
      "Iter 4000: loss 188.606.\n",
      "Iter 5000: loss 117.992.\n",
      "Iter 6000: loss 139.166.\n",
      "Iter 7000: loss 162.348.\n",
      "Iter 8000: loss 143.079.\n",
      "Iter 9000: loss 165.647.\n",
      "\n",
      "\n",
      "Currently at stage 14. Reinforce: False\n",
      "Iter 1000: loss 100.422.\n",
      "Iter 2000: loss 131.409.\n",
      "Iter 3000: loss 125.337.\n",
      "Iter 4000: loss 94.033.\n",
      "Iter 5000: loss 91.825.\n",
      "Iter 6000: loss 132.004.\n",
      "Iter 7000: loss 92.876.\n",
      "Iter 8000: loss 126.495.\n",
      "Iter 9000: loss 126.571.\n",
      "\n",
      "\n",
      "Currently at stage 15. Reinforce: True\n",
      "Iter 1000: loss 80.035.\n",
      "Iter 2000: loss 102.579.\n",
      "Iter 3000: loss 148.618.\n",
      "Iter 4000: loss 113.171.\n",
      "Iter 5000: loss 116.501.\n",
      "Iter 6000: loss 112.574.\n",
      "Iter 7000: loss 156.699.\n",
      "Iter 8000: loss 89.743.\n",
      "Iter 9000: loss 64.919.\n",
      "Iter 10000: loss 43.332.\n",
      "\n",
      "\n",
      "Currently at stage 16. Reinforce: True\n",
      "Iter 1000: loss 98.647.\n",
      "Iter 2000: loss 120.397.\n",
      "Iter 3000: loss 85.956.\n",
      "Iter 4000: loss 142.908.\n",
      "Iter 5000: loss 134.651.\n",
      "Iter 6000: loss 65.073.\n",
      "Iter 7000: loss 187.502.\n",
      "Iter 8000: loss 109.410.\n",
      "Iter 9000: loss 97.959.\n",
      "Iter 10000: loss 64.780.\n",
      "\n",
      "\n",
      "Currently at stage 17. Reinforce: True\n",
      "Iter 1000: loss 99.998.\n",
      "Iter 2000: loss 94.630.\n",
      "Iter 3000: loss 75.022.\n",
      "Iter 4000: loss 117.922.\n",
      "Iter 5000: loss 85.917.\n",
      "Iter 6000: loss 76.404.\n",
      "Iter 7000: loss 120.906.\n",
      "Iter 8000: loss 61.374.\n",
      "Iter 9000: loss 74.715.\n",
      "Iter 10000: loss 61.725.\n",
      "Iter 11000: loss 82.851.\n",
      "\n",
      "\n",
      "Currently at stage 18. Reinforce: True\n",
      "Iter 1000: loss 141.651.\n",
      "Iter 2000: loss 71.229.\n",
      "Iter 3000: loss 62.522.\n",
      "Iter 4000: loss 84.269.\n",
      "Iter 5000: loss 49.149.\n",
      "Iter 6000: loss 73.190.\n",
      "Iter 7000: loss 39.314.\n",
      "Iter 8000: loss 95.007.\n",
      "Iter 9000: loss 139.359.\n",
      "Iter 10000: loss 153.374.\n",
      "Iter 11000: loss 96.877.\n",
      "Iter 12000: loss 61.751.\n",
      "\n",
      "\n",
      "Currently at stage 19. Reinforce: True\n",
      "Iter 1000: loss 83.572.\n",
      "Iter 2000: loss 84.039.\n",
      "Iter 3000: loss 51.578.\n",
      "Iter 4000: loss 61.343.\n",
      "Iter 5000: loss 50.956.\n",
      "Iter 6000: loss 94.401.\n",
      "Iter 7000: loss 60.651.\n",
      "Iter 8000: loss 95.622.\n",
      "Iter 9000: loss 81.359.\n",
      "Iter 10000: loss 58.193.\n",
      "Iter 11000: loss 63.097.\n",
      "Iter 12000: loss 85.091.\n",
      "\n",
      "\n",
      "Currently at stage 20. Reinforce: True\n",
      "Iter 1000: loss 102.307.\n",
      "Iter 2000: loss 34.450.\n",
      "Iter 3000: loss 69.435.\n",
      "Iter 4000: loss 58.741.\n",
      "Iter 5000: loss 73.169.\n",
      "Iter 6000: loss 70.057.\n",
      "Iter 7000: loss 70.106.\n",
      "Iter 8000: loss 12.201.\n",
      "Iter 9000: loss 92.340.\n",
      "Iter 10000: loss 46.612.\n",
      "Iter 11000: loss 83.428.\n",
      "Iter 12000: loss 58.418.\n",
      "Iter 13000: loss 71.073.\n",
      "\n",
      "Done OCF training.\n",
      "Training takes 0.44083333333333335 hours\n"
     ]
    }
   ],
   "source": [
    "# Shape boundary, first order.\n",
    "env_name = 'shape_boundary'\n",
    "c = 1.05\n",
    "num_optimize_iters = [int(5000 * (c**i)) for i in range(21)]\n",
    "train_helper(env_name, num_optimize_iters, warm_up_threshold=15, zero_order=False, save_interval=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd547597",
   "metadata": {},
   "source": [
    "**SHAPE WITH TOPO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de018294",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparams: Rate: 20.000, num traj: 128, step size: 0.01000, lr: 0.00100, batch_size: 32, log_interval:1000\n",
      "\n",
      "\n",
      "Currently at stage 0. Reinforce: False\n",
      "Iter 1000: loss 0.233.\n",
      "Iter 2000: loss 0.088.\n",
      "Iter 3000: loss 0.070.\n",
      "Iter 4000: loss 0.066.\n",
      "Iter 5000: loss 0.061.\n",
      "Iter 6000: loss 0.058.\n",
      "Iter 7000: loss 0.051.\n",
      "Iter 8000: loss 0.052.\n",
      "Iter 9000: loss 0.048.\n",
      "Iter 10000: loss 0.048.\n",
      "\n",
      "\n",
      "Currently at stage 1. Reinforce: False\n",
      "Iter 1000: loss 0.105.\n",
      "Iter 2000: loss 0.067.\n",
      "Iter 3000: loss 0.056.\n",
      "Iter 4000: loss 0.058.\n",
      "Iter 5000: loss 0.053.\n",
      "Iter 6000: loss 0.048.\n",
      "Iter 7000: loss 0.048.\n",
      "Iter 8000: loss 0.046.\n",
      "Iter 9000: loss 0.041.\n",
      "Iter 10000: loss 0.042.\n",
      "\n",
      "\n",
      "Currently at stage 2. Reinforce: False\n",
      "Iter 1000: loss 0.092.\n",
      "Iter 2000: loss 0.050.\n",
      "Iter 3000: loss 0.048.\n",
      "Iter 4000: loss 0.048.\n",
      "Iter 5000: loss 0.045.\n",
      "Iter 6000: loss 0.043.\n",
      "Iter 7000: loss 0.042.\n",
      "Iter 8000: loss 0.043.\n",
      "Iter 9000: loss 0.040.\n",
      "Iter 10000: loss 0.038.\n",
      "Iter 11000: loss 0.038.\n",
      "\n",
      "\n",
      "Currently at stage 3. Reinforce: False\n",
      "Iter 1000: loss 0.088.\n",
      "Iter 2000: loss 0.045.\n",
      "Iter 3000: loss 0.042.\n",
      "Iter 4000: loss 0.043.\n",
      "Iter 5000: loss 0.042.\n",
      "Iter 6000: loss 0.039.\n",
      "Iter 7000: loss 0.041.\n",
      "Iter 8000: loss 0.039.\n",
      "Iter 9000: loss 0.040.\n",
      "Iter 10000: loss 0.036.\n",
      "Iter 11000: loss 0.038.\n",
      "\n",
      "\n",
      "Currently at stage 4. Reinforce: False\n",
      "Iter 1000: loss 0.062.\n",
      "Iter 2000: loss 0.039.\n",
      "Iter 3000: loss 0.038.\n",
      "Iter 4000: loss 0.036.\n",
      "Iter 5000: loss 0.037.\n",
      "Iter 6000: loss 0.034.\n",
      "Iter 7000: loss 0.035.\n",
      "Iter 8000: loss 0.035.\n",
      "Iter 9000: loss 0.035.\n",
      "Iter 10000: loss 0.032.\n",
      "Iter 11000: loss 0.033.\n",
      "Iter 12000: loss 0.032.\n",
      "\n",
      "\n",
      "Currently at stage 5. Reinforce: False\n",
      "Iter 1000: loss 0.066.\n",
      "Iter 2000: loss 0.039.\n",
      "Iter 3000: loss 0.037.\n",
      "Iter 4000: loss 0.034.\n",
      "Iter 5000: loss 0.036.\n",
      "Iter 6000: loss 0.033.\n",
      "Iter 7000: loss 0.034.\n",
      "Iter 8000: loss 0.033.\n",
      "Iter 9000: loss 0.032.\n",
      "Iter 10000: loss 0.035.\n",
      "Iter 11000: loss 0.032.\n",
      "Iter 12000: loss 0.031.\n",
      "\n",
      "\n",
      "Currently at stage 6. Reinforce: False\n",
      "Iter 1000: loss 0.056.\n",
      "Iter 2000: loss 0.034.\n",
      "Iter 3000: loss 0.035.\n",
      "Iter 4000: loss 0.033.\n",
      "Iter 5000: loss 0.032.\n",
      "Iter 6000: loss 0.032.\n",
      "Iter 7000: loss 0.033.\n",
      "Iter 8000: loss 0.032.\n",
      "Iter 9000: loss 0.032.\n",
      "Iter 10000: loss 0.031.\n",
      "Iter 11000: loss 0.030.\n",
      "Iter 12000: loss 0.031.\n",
      "Iter 13000: loss 0.031.\n",
      "\n",
      "\n",
      "Currently at stage 7. Reinforce: False\n",
      "Iter 1000: loss 0.063.\n",
      "Iter 2000: loss 0.036.\n",
      "Iter 3000: loss 0.033.\n",
      "Iter 4000: loss 0.033.\n",
      "Iter 5000: loss 0.032.\n",
      "Iter 6000: loss 0.032.\n",
      "Iter 7000: loss 0.033.\n",
      "Iter 8000: loss 0.031.\n",
      "Iter 9000: loss 0.031.\n",
      "Iter 10000: loss 0.031.\n",
      "Iter 11000: loss 0.030.\n",
      "Iter 12000: loss 0.032.\n",
      "Iter 13000: loss 0.030.\n",
      "Iter 14000: loss 0.031.\n",
      "\n",
      "\n",
      "Currently at stage 8. Reinforce: False\n",
      "Iter 1000: loss 0.052.\n",
      "Iter 2000: loss 0.031.\n",
      "Iter 3000: loss 0.034.\n",
      "Iter 4000: loss 0.033.\n",
      "Iter 5000: loss 0.031.\n",
      "Iter 6000: loss 0.032.\n",
      "Iter 7000: loss 0.031.\n",
      "Iter 8000: loss 0.032.\n",
      "Iter 9000: loss 0.030.\n",
      "Iter 10000: loss 0.030.\n",
      "Iter 11000: loss 0.031.\n",
      "Iter 12000: loss 0.029.\n",
      "Iter 13000: loss 0.030.\n",
      "Iter 14000: loss 0.030.\n",
      "\n",
      "\n",
      "Currently at stage 9. Reinforce: False\n",
      "Iter 1000: loss 0.049.\n",
      "Iter 2000: loss 0.034.\n",
      "Iter 3000: loss 0.032.\n",
      "Iter 4000: loss 0.033.\n",
      "Iter 5000: loss 0.031.\n",
      "Iter 6000: loss 0.031.\n",
      "Iter 7000: loss 0.032.\n",
      "Iter 8000: loss 0.030.\n",
      "Iter 9000: loss 0.032.\n",
      "Iter 10000: loss 0.031.\n",
      "Iter 11000: loss 0.030.\n",
      "Iter 12000: loss 0.031.\n",
      "Iter 13000: loss 0.029.\n",
      "Iter 14000: loss 0.030.\n",
      "Iter 15000: loss 0.030.\n",
      "\n",
      "\n",
      "Currently at stage 10. Reinforce: False\n",
      "Iter 1000: loss 0.047.\n",
      "Iter 2000: loss 0.033.\n",
      "Iter 3000: loss 0.031.\n",
      "Iter 4000: loss 0.031.\n",
      "Iter 5000: loss 0.032.\n",
      "Iter 6000: loss 0.031.\n",
      "Iter 7000: loss 0.032.\n",
      "Iter 8000: loss 0.030.\n",
      "Iter 9000: loss 0.031.\n",
      "Iter 10000: loss 0.031.\n",
      "Iter 11000: loss 0.030.\n",
      "Iter 12000: loss 0.030.\n",
      "Iter 13000: loss 0.031.\n",
      "Iter 14000: loss 0.030.\n",
      "Iter 15000: loss 0.030.\n",
      "Iter 16000: loss 0.031.\n",
      "\n",
      "\n",
      "Currently at stage 11. Reinforce: False\n",
      "Iter 1000: loss 0.047.\n",
      "Iter 2000: loss 0.033.\n",
      "Iter 3000: loss 0.032.\n",
      "Iter 4000: loss 0.033.\n",
      "Iter 5000: loss 0.031.\n",
      "Iter 6000: loss 0.031.\n",
      "Iter 7000: loss 0.032.\n",
      "Iter 8000: loss 0.031.\n",
      "Iter 9000: loss 0.031.\n",
      "Iter 10000: loss 0.031.\n",
      "Iter 11000: loss 0.032.\n",
      "Iter 12000: loss 0.031.\n",
      "Iter 13000: loss 0.031.\n",
      "Iter 14000: loss 0.031.\n",
      "Iter 15000: loss 0.030.\n",
      "Iter 16000: loss 0.030.\n",
      "Iter 17000: loss 0.030.\n",
      "\n",
      "\n",
      "Currently at stage 12. Reinforce: False\n",
      "Iter 1000: loss 0.052.\n",
      "Iter 2000: loss 0.034.\n",
      "Iter 3000: loss 0.033.\n",
      "Iter 4000: loss 0.033.\n",
      "Iter 5000: loss 0.033.\n",
      "Iter 6000: loss 0.031.\n",
      "Iter 7000: loss 0.032.\n",
      "Iter 8000: loss 0.031.\n",
      "Iter 9000: loss 0.032.\n",
      "Iter 10000: loss 0.031.\n",
      "Iter 11000: loss 0.032.\n",
      "Iter 12000: loss 0.031.\n",
      "Iter 13000: loss 0.031.\n",
      "Iter 14000: loss 0.033.\n",
      "Iter 15000: loss 0.031.\n",
      "Iter 16000: loss 0.032.\n",
      "Iter 17000: loss 0.031.\n",
      "\n",
      "\n",
      "Currently at stage 13. Reinforce: False\n",
      "Iter 1000: loss 0.046.\n",
      "Iter 2000: loss 0.034.\n",
      "Iter 3000: loss 0.034.\n",
      "Iter 4000: loss 0.033.\n",
      "Iter 5000: loss 0.033.\n",
      "Iter 6000: loss 0.032.\n",
      "Iter 7000: loss 0.033.\n",
      "Iter 8000: loss 0.032.\n",
      "Iter 9000: loss 0.033.\n",
      "Iter 10000: loss 0.033.\n",
      "Iter 11000: loss 0.032.\n",
      "Iter 12000: loss 0.032.\n",
      "Iter 13000: loss 0.033.\n",
      "Iter 14000: loss 0.032.\n",
      "Iter 15000: loss 0.033.\n",
      "Iter 16000: loss 0.032.\n",
      "Iter 17000: loss 0.032.\n",
      "Iter 18000: loss 0.031.\n",
      "\n",
      "\n",
      "Currently at stage 14. Reinforce: False\n",
      "Iter 1000: loss 0.060.\n",
      "Iter 2000: loss 0.040.\n",
      "Iter 3000: loss 0.035.\n",
      "Iter 4000: loss 0.034.\n",
      "Iter 5000: loss 0.035.\n",
      "Iter 6000: loss 0.034.\n",
      "Iter 7000: loss 0.033.\n",
      "Iter 8000: loss 0.033.\n",
      "Iter 9000: loss 0.033.\n",
      "Iter 10000: loss 0.032.\n",
      "Iter 11000: loss 0.032.\n",
      "Iter 12000: loss 0.033.\n",
      "Iter 13000: loss 0.034.\n",
      "Iter 14000: loss 0.033.\n",
      "Iter 15000: loss 0.033.\n",
      "Iter 16000: loss 0.033.\n",
      "Iter 17000: loss 0.032.\n",
      "Iter 18000: loss 0.033.\n",
      "Iter 19000: loss 0.033.\n",
      "\n",
      "\n",
      "Currently at stage 15. Reinforce: True\n",
      "Iter 1000: loss 0.061.\n",
      "Iter 2000: loss 0.057.\n",
      "Iter 3000: loss 0.057.\n",
      "Iter 4000: loss 0.055.\n",
      "Iter 5000: loss 0.055.\n",
      "Iter 6000: loss 0.058.\n",
      "Iter 7000: loss 0.058.\n",
      "Iter 8000: loss 0.056.\n",
      "Iter 9000: loss 0.056.\n",
      "Iter 10000: loss 0.056.\n",
      "Iter 11000: loss 0.055.\n",
      "Iter 12000: loss 0.055.\n",
      "Iter 13000: loss 0.054.\n",
      "Iter 14000: loss 0.055.\n",
      "Iter 15000: loss 0.053.\n",
      "Iter 16000: loss 0.054.\n",
      "Iter 17000: loss 0.053.\n",
      "Iter 18000: loss 0.052.\n",
      "Iter 19000: loss 0.053.\n",
      "Iter 20000: loss 0.053.\n",
      "\n",
      "\n",
      "Currently at stage 16. Reinforce: True\n",
      "Iter 1000: loss 0.083.\n",
      "Iter 2000: loss 0.078.\n",
      "Iter 3000: loss 0.078.\n",
      "Iter 4000: loss 0.077.\n",
      "Iter 5000: loss 0.077.\n",
      "Iter 6000: loss 0.075.\n",
      "Iter 7000: loss 0.074.\n",
      "Iter 8000: loss 0.074.\n",
      "Iter 9000: loss 0.074.\n",
      "Iter 10000: loss 0.074.\n",
      "Iter 11000: loss 0.073.\n",
      "Iter 12000: loss 0.074.\n",
      "Iter 13000: loss 0.073.\n",
      "Iter 14000: loss 0.073.\n",
      "Iter 15000: loss 0.073.\n",
      "Iter 16000: loss 0.071.\n",
      "Iter 17000: loss 0.070.\n",
      "Iter 18000: loss 0.070.\n",
      "Iter 19000: loss 0.069.\n",
      "Iter 20000: loss 0.067.\n",
      "Iter 21000: loss 0.069.\n",
      "\n",
      "\n",
      "Currently at stage 17. Reinforce: True\n",
      "Iter 1000: loss 0.090.\n",
      "Iter 2000: loss 0.088.\n",
      "Iter 3000: loss 0.087.\n",
      "Iter 4000: loss 0.084.\n",
      "Iter 5000: loss 0.082.\n",
      "Iter 6000: loss 0.083.\n",
      "Iter 7000: loss 0.082.\n",
      "Iter 8000: loss 0.083.\n",
      "Iter 9000: loss 0.082.\n",
      "Iter 10000: loss 0.082.\n",
      "Iter 11000: loss 0.080.\n",
      "Iter 12000: loss 0.081.\n",
      "Iter 13000: loss 0.082.\n",
      "Iter 14000: loss 0.081.\n",
      "Iter 15000: loss 0.082.\n",
      "Iter 16000: loss 0.078.\n",
      "Iter 17000: loss 0.078.\n",
      "Iter 18000: loss 0.078.\n",
      "Iter 19000: loss 0.080.\n",
      "Iter 20000: loss 0.078.\n",
      "Iter 21000: loss 0.078.\n",
      "Iter 22000: loss 0.079.\n",
      "\n",
      "\n",
      "Currently at stage 18. Reinforce: True\n",
      "Iter 1000: loss 0.105.\n",
      "Iter 2000: loss 0.099.\n",
      "Iter 3000: loss 0.095.\n",
      "Iter 4000: loss 0.094.\n",
      "Iter 5000: loss 0.092.\n",
      "Iter 6000: loss 0.092.\n",
      "Iter 7000: loss 0.094.\n",
      "Iter 8000: loss 0.094.\n",
      "Iter 9000: loss 0.088.\n",
      "Iter 10000: loss 0.091.\n",
      "Iter 11000: loss 0.090.\n",
      "Iter 12000: loss 0.089.\n",
      "Iter 13000: loss 0.088.\n",
      "Iter 14000: loss 0.087.\n",
      "Iter 15000: loss 0.090.\n",
      "Iter 16000: loss 0.088.\n",
      "Iter 17000: loss 0.089.\n",
      "Iter 18000: loss 0.088.\n",
      "Iter 19000: loss 0.089.\n",
      "Iter 20000: loss 0.089.\n",
      "Iter 21000: loss 0.085.\n",
      "Iter 22000: loss 0.086.\n",
      "Iter 23000: loss 0.085.\n",
      "Iter 24000: loss 0.088.\n",
      "\n",
      "\n",
      "Currently at stage 19. Reinforce: True\n",
      "Iter 1000: loss 0.108.\n",
      "Iter 2000: loss 0.103.\n",
      "Iter 3000: loss 0.102.\n",
      "Iter 4000: loss 0.098.\n",
      "Iter 5000: loss 0.098.\n",
      "Iter 6000: loss 0.096.\n",
      "Iter 7000: loss 0.097.\n",
      "Iter 8000: loss 0.094.\n",
      "Iter 9000: loss 0.095.\n",
      "Iter 10000: loss 0.095.\n",
      "Iter 11000: loss 0.092.\n",
      "Iter 12000: loss 0.094.\n",
      "Iter 13000: loss 0.094.\n",
      "Iter 14000: loss 0.093.\n",
      "Iter 15000: loss 0.091.\n",
      "Iter 16000: loss 0.091.\n",
      "Iter 17000: loss 0.093.\n",
      "Iter 18000: loss 0.089.\n",
      "Iter 19000: loss 0.092.\n",
      "Iter 20000: loss 0.088.\n",
      "Iter 21000: loss 0.089.\n",
      "Iter 22000: loss 0.089.\n",
      "Iter 23000: loss 0.093.\n",
      "Iter 24000: loss 0.088.\n",
      "Iter 25000: loss 0.089.\n",
      "\n",
      "\n",
      "Currently at stage 20. Reinforce: True\n",
      "Iter 1000: loss 0.102.\n",
      "Iter 2000: loss 0.099.\n",
      "Iter 3000: loss 0.095.\n",
      "Iter 4000: loss 0.095.\n",
      "Iter 5000: loss 0.094.\n",
      "Iter 6000: loss 0.090.\n",
      "Iter 7000: loss 0.093.\n",
      "Iter 8000: loss 0.091.\n",
      "Iter 9000: loss 0.090.\n",
      "Iter 10000: loss 0.089.\n",
      "Iter 11000: loss 0.089.\n",
      "Iter 12000: loss 0.090.\n",
      "Iter 13000: loss 0.088.\n",
      "Iter 14000: loss 0.088.\n",
      "Iter 15000: loss 0.090.\n",
      "Iter 16000: loss 0.089.\n",
      "Iter 17000: loss 0.087.\n",
      "Iter 18000: loss 0.087.\n",
      "Iter 19000: loss 0.088.\n",
      "Iter 20000: loss 0.088.\n",
      "Iter 21000: loss 0.086.\n",
      "Iter 22000: loss 0.085.\n",
      "Iter 23000: loss 0.085.\n",
      "Iter 24000: loss 0.085.\n",
      "Iter 25000: loss 0.085.\n",
      "Iter 26000: loss 0.085.\n",
      "\n",
      "Done OCF training.\n",
      "Training takes 0.8194444444444444 hours\n"
     ]
    }
   ],
   "source": [
    "# Shape, zero order.\n",
    "env_name = 'shape'\n",
    "c = 1.05\n",
    "num_optimize_iters = [int(10000 * (c**i)) for i in range(21)]\n",
    "train_helper(env_name, num_optimize_iters, warm_up_threshold=15, zero_order=True, save_interval=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2447453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparams: Rate: 20.000, num traj: 128, step size: 0.01000, lr: 0.00100, batch_size: 32, log_interval:1000\n",
      "\n",
      "\n",
      "Currently at stage 0. Reinforce: False\n",
      "Iter 1000: loss 0.001.\n",
      "Iter 2000: loss 0.000.\n",
      "Iter 3000: loss 0.000.\n",
      "Iter 4000: loss 0.000.\n",
      "Iter 5000: loss 0.000.\n",
      "\n",
      "\n",
      "Currently at stage 1. Reinforce: False\n",
      "Iter 1000: loss 0.000.\n",
      "Iter 2000: loss 0.000.\n",
      "Iter 3000: loss 0.000.\n",
      "Iter 4000: loss 0.000.\n",
      "Iter 5000: loss 0.000.\n",
      "\n",
      "\n",
      "Currently at stage 2. Reinforce: False\n",
      "Iter 1000: loss 0.000.\n",
      "Iter 2000: loss 0.000.\n",
      "Iter 3000: loss 0.000.\n",
      "Iter 4000: loss 0.000.\n",
      "Iter 5000: loss 0.000.\n",
      "\n",
      "\n",
      "Currently at stage 3. Reinforce: False\n",
      "Iter 1000: loss 0.000.\n",
      "Iter 2000: loss 0.000.\n",
      "Iter 3000: loss 0.000.\n",
      "Iter 4000: loss 0.000.\n",
      "Iter 5000: loss 0.000.\n",
      "\n",
      "\n",
      "Currently at stage 4. Reinforce: False\n",
      "Iter 1000: loss 0.000.\n",
      "Iter 2000: loss 0.000.\n",
      "Iter 3000: loss 0.000.\n",
      "Iter 4000: loss 0.000.\n",
      "Iter 5000: loss 0.000.\n",
      "Iter 6000: loss 0.000.\n",
      "\n",
      "\n",
      "Currently at stage 5. Reinforce: False\n",
      "Iter 1000: loss 0.000.\n",
      "Iter 2000: loss 0.000.\n",
      "Iter 3000: loss 0.000.\n",
      "Iter 4000: loss 0.000.\n",
      "Iter 5000: loss 0.000.\n",
      "Iter 6000: loss 0.000.\n",
      "\n",
      "\n",
      "Currently at stage 6. Reinforce: False\n",
      "Iter 1000: loss 1.124.\n",
      "Iter 2000: loss 1.133.\n",
      "Iter 3000: loss 1.276.\n",
      "Iter 4000: loss 1.026.\n",
      "Iter 5000: loss 0.825.\n",
      "Iter 6000: loss 1.110.\n",
      "\n",
      "\n",
      "Currently at stage 7. Reinforce: False\n",
      "Iter 1000: loss 1.149.\n",
      "Iter 2000: loss 1.109.\n",
      "Iter 3000: loss 0.809.\n",
      "Iter 4000: loss 0.825.\n",
      "Iter 5000: loss 0.658.\n",
      "Iter 6000: loss 1.027.\n",
      "Iter 7000: loss 1.061.\n",
      "\n",
      "\n",
      "Currently at stage 8. Reinforce: False\n",
      "Iter 1000: loss 0.823.\n",
      "Iter 2000: loss 0.935.\n",
      "Iter 3000: loss 0.910.\n",
      "Iter 4000: loss 0.569.\n",
      "Iter 5000: loss 0.519.\n",
      "Iter 6000: loss 0.719.\n",
      "Iter 7000: loss 0.791.\n",
      "\n",
      "\n",
      "Currently at stage 9. Reinforce: False\n",
      "Iter 1000: loss 0.900.\n",
      "Iter 2000: loss 1.476.\n",
      "Iter 3000: loss 1.090.\n",
      "Iter 4000: loss 1.066.\n",
      "Iter 5000: loss 0.890.\n",
      "Iter 6000: loss 0.977.\n",
      "Iter 7000: loss 1.330.\n",
      "\n",
      "\n",
      "Currently at stage 10. Reinforce: False\n",
      "Iter 1000: loss 1.124.\n",
      "Iter 2000: loss 1.143.\n",
      "Iter 3000: loss 1.097.\n",
      "Iter 4000: loss 1.306.\n",
      "Iter 5000: loss 0.969.\n",
      "Iter 6000: loss 0.974.\n",
      "Iter 7000: loss 1.391.\n",
      "Iter 8000: loss 0.955.\n",
      "\n",
      "\n",
      "Currently at stage 11. Reinforce: False\n",
      "Iter 1000: loss 0.756.\n",
      "Iter 2000: loss 0.793.\n",
      "Iter 3000: loss 0.982.\n",
      "Iter 4000: loss 0.947.\n",
      "Iter 5000: loss 1.062.\n",
      "Iter 6000: loss 0.982.\n",
      "Iter 7000: loss 1.057.\n",
      "Iter 8000: loss 0.747.\n",
      "\n",
      "\n",
      "Currently at stage 12. Reinforce: False\n",
      "Iter 1000: loss 1.085.\n",
      "Iter 2000: loss 0.642.\n",
      "Iter 3000: loss 1.262.\n",
      "Iter 4000: loss 0.947.\n",
      "Iter 5000: loss 0.955.\n",
      "Iter 6000: loss 0.797.\n",
      "Iter 7000: loss 0.929.\n",
      "Iter 8000: loss 0.839.\n",
      "\n",
      "\n",
      "Currently at stage 13. Reinforce: False\n",
      "Iter 1000: loss 1.812.\n",
      "Iter 2000: loss 1.880.\n",
      "Iter 3000: loss 2.218.\n",
      "Iter 4000: loss 1.939.\n",
      "Iter 5000: loss 2.068.\n",
      "Iter 6000: loss 1.709.\n",
      "Iter 7000: loss 2.113.\n",
      "Iter 8000: loss 1.812.\n",
      "Iter 9000: loss 1.948.\n",
      "\n",
      "\n",
      "Currently at stage 14. Reinforce: False\n",
      "Iter 1000: loss 2.203.\n",
      "Iter 2000: loss 2.438.\n",
      "Iter 3000: loss 2.423.\n",
      "Iter 4000: loss 1.896.\n",
      "Iter 5000: loss 2.150.\n",
      "Iter 6000: loss 1.750.\n",
      "Iter 7000: loss 1.607.\n",
      "Iter 8000: loss 2.226.\n",
      "Iter 9000: loss 1.691.\n",
      "\n",
      "\n",
      "Currently at stage 15. Reinforce: True\n",
      "Iter 1000: loss 1.655.\n",
      "Iter 2000: loss 1.569.\n",
      "Iter 3000: loss 1.592.\n",
      "Iter 4000: loss 1.995.\n",
      "Iter 5000: loss 1.707.\n",
      "Iter 6000: loss 1.724.\n",
      "Iter 7000: loss 1.713.\n",
      "Iter 8000: loss 1.402.\n",
      "Iter 9000: loss 1.354.\n",
      "Iter 10000: loss 1.329.\n",
      "\n",
      "\n",
      "Currently at stage 16. Reinforce: True\n",
      "Iter 1000: loss 1.559.\n",
      "Iter 2000: loss 1.449.\n",
      "Iter 3000: loss 1.458.\n",
      "Iter 4000: loss 1.655.\n",
      "Iter 5000: loss 1.311.\n",
      "Iter 6000: loss 1.275.\n",
      "Iter 7000: loss 1.414.\n",
      "Iter 8000: loss 1.473.\n",
      "Iter 9000: loss 1.608.\n",
      "Iter 10000: loss 1.677.\n",
      "\n",
      "\n",
      "Currently at stage 17. Reinforce: True\n",
      "Iter 1000: loss 1.132.\n",
      "Iter 2000: loss 1.415.\n",
      "Iter 3000: loss 1.265.\n",
      "Iter 4000: loss 1.349.\n",
      "Iter 5000: loss 1.691.\n",
      "Iter 6000: loss 1.503.\n",
      "Iter 7000: loss 1.654.\n",
      "Iter 8000: loss 1.308.\n",
      "Iter 9000: loss 1.148.\n",
      "Iter 10000: loss 1.232.\n",
      "Iter 11000: loss 1.058.\n",
      "\n",
      "\n",
      "Currently at stage 18. Reinforce: True\n",
      "Iter 1000: loss 1.081.\n",
      "Iter 2000: loss 1.225.\n",
      "Iter 3000: loss 1.410.\n",
      "Iter 4000: loss 1.075.\n",
      "Iter 5000: loss 0.966.\n",
      "Iter 6000: loss 0.841.\n",
      "Iter 7000: loss 1.322.\n",
      "Iter 8000: loss 1.371.\n",
      "Iter 9000: loss 1.724.\n",
      "Iter 10000: loss 1.236.\n",
      "Iter 11000: loss 1.407.\n",
      "Iter 12000: loss 1.297.\n",
      "\n",
      "\n",
      "Currently at stage 19. Reinforce: True\n",
      "Iter 1000: loss 1.373.\n",
      "Iter 2000: loss 0.929.\n",
      "Iter 3000: loss 1.092.\n",
      "Iter 4000: loss 1.228.\n",
      "Iter 5000: loss 0.911.\n",
      "Iter 6000: loss 1.188.\n",
      "Iter 7000: loss 1.209.\n",
      "Iter 8000: loss 0.832.\n",
      "Iter 9000: loss 1.057.\n",
      "Iter 10000: loss 1.083.\n",
      "Iter 11000: loss 1.144.\n",
      "Iter 12000: loss 1.234.\n",
      "\n",
      "\n",
      "Currently at stage 20. Reinforce: True\n",
      "Iter 1000: loss 1.241.\n",
      "Iter 2000: loss 1.150.\n",
      "Iter 3000: loss 1.191.\n",
      "Iter 4000: loss 1.249.\n",
      "Iter 5000: loss 0.928.\n",
      "Iter 6000: loss 1.327.\n",
      "Iter 7000: loss 1.229.\n",
      "Iter 8000: loss 1.266.\n",
      "Iter 9000: loss 0.908.\n",
      "Iter 10000: loss 1.042.\n",
      "Iter 11000: loss 0.798.\n",
      "Iter 12000: loss 1.208.\n",
      "Iter 13000: loss 1.058.\n",
      "\n",
      "Done OCF training.\n",
      "Training takes 0.6788888888888889 hours\n"
     ]
    }
   ],
   "source": [
    "# Shape, first order.\n",
    "env_name = 'shape'\n",
    "c = 1.05\n",
    "num_optimize_iters = [int(5000 * (c**i)) for i in range(21)]\n",
    "train_helper(env_name, num_optimize_iters, warm_up_threshold=15, zero_order=False, save_interval=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82deaa3",
   "metadata": {},
   "source": [
    "**MOLECULE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dcc42541",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import train\n",
    "import time\n",
    "def train_helper(env_name, num_optimize_iters, warm_up_threshold, zero_order, save_interval):\n",
    "    start_time = time.time()\n",
    "    train(env_name, num_optimize_iters, warm_up_threshold, zero_order, save_interval)\n",
    "    print('Training takes {} hours'.format(int(time.time()-start_time)/3600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "938532c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparams: Rate: 25.000, num traj: 128, step size: 0.01000, lr: 0.00100, batch_size: 64, log_interval:1000\n",
      "core.chemical.GlobalResidueTypeSet: Finished initializing fa_standard residue type set.  Created 985 residue types\n",
      "core.chemical.GlobalResidueTypeSet: Total time to initialize 1.18824 seconds.\n",
      "core.scoring.ScoreFunctionFactory: SCOREFUNCTION: ref2015\n",
      "core.scoring.etable: Starting energy table calculation\n",
      "core.scoring.etable: smooth_etable: changing atr/rep split to bottom of energy well\n",
      "core.scoring.etable: smooth_etable: spline smoothing lj etables (maxdis = 6)\n",
      "core.scoring.etable: smooth_etable: spline smoothing solvation etables (max_dis = 6)\n",
      "core.scoring.etable: Finished calculating energy tables.\n",
      "basic.io.database: Database file opened: scoring/score_functions/hbonds/ref2015_params/HBPoly1D.csv\n",
      "basic.io.database: Database file opened: scoring/score_functions/hbonds/ref2015_params/HBFadeIntervals.csv\n",
      "basic.io.database: Database file opened: scoring/score_functions/hbonds/ref2015_params/HBEval.csv\n",
      "basic.io.database: Database file opened: scoring/score_functions/hbonds/ref2015_params/DonStrength.csv\n",
      "basic.io.database: Database file opened: scoring/score_functions/hbonds/ref2015_params/AccStrength.csv\n",
      "basic.io.database: Database file opened: scoring/score_functions/rama/fd/all.ramaProb\n",
      "basic.io.database: Database file opened: scoring/score_functions/rama/fd/prepro.ramaProb\n",
      "basic.io.database: Database file opened: scoring/score_functions/omega/omega_ppdep.all.txt\n",
      "basic.io.database: Database file opened: scoring/score_functions/omega/omega_ppdep.gly.txt\n",
      "basic.io.database: Database file opened: scoring/score_functions/omega/omega_ppdep.pro.txt\n",
      "basic.io.database: Database file opened: scoring/score_functions/omega/omega_ppdep.valile.txt\n",
      "basic.io.database: Database file opened: scoring/score_functions/P_AA_pp/P_AA\n",
      "basic.io.database: Database file opened: scoring/score_functions/P_AA_pp/P_AA_n\n",
      "core.scoring.P_AA: shapovalov_lib::shap_p_aa_pp_smooth_level of 1( aka low_smooth ) got activated.\n",
      "basic.io.database: Database file opened: scoring/score_functions/P_AA_pp/shapovalov/10deg/kappa131/a20.prop\n",
      "\n",
      "\n",
      "Currently at stage 0. Reinforce: False\n",
      "basic.io.database: Database file opened: scoring/score_functions/elec_cp_reps.dat\n",
      "core.scoring.elec.util: Read 40 countpair representative atoms\n",
      "core.pack.dunbrack.RotamerLibrary: shapovalov_lib_fixes_enable option is true.\n",
      "core.pack.dunbrack.RotamerLibrary: shapovalov_lib::shap_dun10_smooth_level of 1( aka lowest_smooth ) got activated.\n",
      "core.pack.dunbrack.RotamerLibrary: Binary rotamer library selected: /home/erickim/pyro-env-py39/lib/python3.9/site-packages/pyrosetta/database/rotamer/shapovalov/StpDwn_0-0-0/Dunbrack10.lib.bin\n",
      "core.pack.dunbrack.RotamerLibrary: Using Dunbrack library binary file '/home/erickim/pyro-env-py39/lib/python3.9/site-packages/pyrosetta/database/rotamer/shapovalov/StpDwn_0-0-0/Dunbrack10.lib.bin'.\n",
      "core.pack.dunbrack.RotamerLibrary: Dunbrack 2010 library took 0.656842 seconds to load from binary\n",
      "Iter 1000: loss 64.079.\n",
      "\n",
      "\n",
      "Currently at stage 1. Reinforce: False\n",
      "Iter 1000: loss 51.894.\n",
      "\n",
      "\n",
      "Currently at stage 2. Reinforce: False\n",
      "Iter 1000: loss 27.854.\n",
      "Iter 2000: loss 9.747.\n",
      "\n",
      "\n",
      "Currently at stage 3. Reinforce: False\n",
      "Iter 1000: loss 25.786.\n",
      "Iter 2000: loss 9.746.\n",
      "Iter 3000: loss 9.141.\n",
      "\n",
      "\n",
      "Currently at stage 4. Reinforce: False\n",
      "Iter 1000: loss 18.258.\n",
      "Iter 2000: loss 9.539.\n",
      "Iter 3000: loss 8.708.\n",
      "Iter 4000: loss 8.664.\n",
      "Iter 5000: loss 8.176.\n",
      "\n",
      "\n",
      "Currently at stage 5. Reinforce: True\n",
      "Iter 1000: loss 39.776.\n",
      "Iter 2000: loss 31.692.\n",
      "Iter 3000: loss 30.185.\n",
      "Iter 4000: loss 30.789.\n",
      "Iter 5000: loss 28.970.\n",
      "Iter 6000: loss 29.416.\n",
      "Iter 7000: loss 28.504.\n",
      "\n",
      "\n",
      "Currently at stage 6. Reinforce: True\n",
      "Iter 1000: loss 52.027.\n",
      "Iter 2000: loss 50.381.\n",
      "Iter 3000: loss 50.250.\n",
      "Iter 4000: loss 48.016.\n",
      "Iter 5000: loss 48.356.\n",
      "Iter 6000: loss 48.669.\n",
      "Iter 7000: loss 47.943.\n",
      "Iter 8000: loss 47.769.\n",
      "Iter 9000: loss 46.714.\n",
      "Iter 10000: loss 46.763.\n",
      "Iter 11000: loss 47.141.\n",
      "\n",
      "\n",
      "Currently at stage 7. Reinforce: True\n",
      "Iter 1000: loss 62.988.\n",
      "Iter 2000: loss 58.546.\n",
      "Iter 3000: loss 58.347.\n",
      "Iter 4000: loss 57.088.\n",
      "Iter 5000: loss 55.963.\n",
      "Iter 6000: loss 55.937.\n",
      "Iter 7000: loss 56.160.\n",
      "Iter 8000: loss 55.029.\n",
      "Iter 9000: loss 55.457.\n",
      "Iter 10000: loss 54.878.\n",
      "Iter 11000: loss 55.044.\n",
      "Iter 12000: loss 54.772.\n",
      "Iter 13000: loss 54.998.\n",
      "Iter 14000: loss 53.402.\n",
      "Iter 15000: loss 55.227.\n",
      "Iter 16000: loss 54.184.\n",
      "Iter 17000: loss 54.600.\n",
      "\n",
      "\n",
      "Currently at stage 8. Reinforce: True\n",
      "Iter 1000: loss 68.927.\n",
      "Iter 2000: loss 67.549.\n",
      "Iter 3000: loss 68.371.\n",
      "Iter 4000: loss 67.798.\n",
      "Iter 5000: loss 66.658.\n",
      "Iter 6000: loss 67.403.\n",
      "Iter 7000: loss 66.351.\n",
      "Iter 8000: loss 65.870.\n",
      "Iter 9000: loss 65.513.\n",
      "Iter 10000: loss 67.017.\n",
      "Iter 11000: loss 65.499.\n",
      "Iter 12000: loss 65.966.\n",
      "Iter 13000: loss 65.759.\n",
      "Iter 14000: loss 66.055.\n",
      "Iter 15000: loss 64.842.\n",
      "Iter 16000: loss 64.264.\n",
      "Iter 17000: loss 64.352.\n",
      "Iter 18000: loss 64.983.\n",
      "Iter 19000: loss 64.799.\n",
      "Iter 20000: loss 63.995.\n",
      "Iter 21000: loss 65.212.\n",
      "Iter 22000: loss 64.229.\n",
      "Iter 23000: loss 64.896.\n",
      "Iter 24000: loss 65.208.\n",
      "Iter 25000: loss 63.944.\n",
      "\n",
      "\n",
      "Currently at stage 9. Reinforce: True\n",
      "Iter 1000: loss 70.880.\n",
      "Iter 2000: loss 68.980.\n",
      "Iter 3000: loss 67.978.\n",
      "Iter 4000: loss 67.619.\n",
      "Iter 5000: loss 68.047.\n",
      "Iter 6000: loss 68.644.\n",
      "Iter 7000: loss 67.499.\n",
      "Iter 8000: loss 67.091.\n",
      "Iter 9000: loss 67.126.\n",
      "Iter 10000: loss 66.671.\n",
      "Iter 11000: loss 67.058.\n",
      "Iter 12000: loss 67.027.\n",
      "Iter 13000: loss 67.308.\n",
      "Iter 14000: loss 66.535.\n",
      "Iter 15000: loss 68.394.\n",
      "Iter 16000: loss 66.719.\n",
      "Iter 17000: loss 66.641.\n",
      "Iter 18000: loss 66.327.\n",
      "Iter 19000: loss 66.377.\n",
      "Iter 20000: loss 66.569.\n",
      "Iter 21000: loss 66.554.\n",
      "Iter 22000: loss 66.831.\n",
      "Iter 23000: loss 65.951.\n",
      "Iter 24000: loss 67.704.\n",
      "Iter 25000: loss 67.357.\n",
      "Iter 26000: loss 65.762.\n",
      "Iter 27000: loss 65.443.\n",
      "Iter 28000: loss 66.140.\n",
      "Iter 29000: loss 64.743.\n",
      "Iter 30000: loss 66.288.\n",
      "Iter 31000: loss 66.525.\n",
      "Iter 32000: loss 66.329.\n",
      "Iter 33000: loss 66.252.\n",
      "Iter 34000: loss 66.441.\n",
      "Iter 35000: loss 66.949.\n",
      "Iter 36000: loss 66.043.\n",
      "Iter 37000: loss 66.452.\n",
      "Iter 38000: loss 66.764.\n",
      "\n",
      "Done OCF training.\n",
      "Training takes 0.12 hours\n"
     ]
    }
   ],
   "source": [
    "# Molecule zero order.\n",
    "env_name = 'molecule'\n",
    "c = 1.5\n",
    "num_optimize_iters = [int(1000 * (c**i)) for i in range(10)]\n",
    "train_helper(env_name, num_optimize_iters, warm_up_threshold=5, zero_order=True, save_interval=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "236a0810",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparams: Rate: 25.000, num traj: 128, step size: 0.01000, lr: 0.00100, batch_size: 64, log_interval:1000\n",
      "core.scoring.ScoreFunctionFactory: SCOREFUNCTION: ref2015\n",
      "\n",
      "\n",
      "Currently at stage 0. Reinforce: False\n",
      "Iter 1000: loss 0.639.\n",
      "\n",
      "\n",
      "Currently at stage 1. Reinforce: False\n",
      "Iter 1000: loss 0.658.\n",
      "\n",
      "\n",
      "Currently at stage 2. Reinforce: False\n",
      "Iter 1000: loss 0.507.\n",
      "Iter 2000: loss 0.226.\n",
      "\n",
      "\n",
      "Currently at stage 3. Reinforce: False\n",
      "Iter 1000: loss 0.437.\n",
      "Iter 2000: loss 0.225.\n",
      "Iter 3000: loss 0.184.\n",
      "\n",
      "\n",
      "Currently at stage 4. Reinforce: False\n",
      "Iter 1000: loss 0.402.\n",
      "Iter 2000: loss 0.225.\n",
      "Iter 3000: loss 0.189.\n",
      "Iter 4000: loss 0.169.\n",
      "Iter 5000: loss 0.162.\n",
      "\n",
      "\n",
      "Currently at stage 5. Reinforce: True\n",
      "Iter 1000: loss 0.620.\n",
      "Iter 2000: loss 0.548.\n",
      "Iter 3000: loss 0.507.\n",
      "Iter 4000: loss 0.492.\n",
      "Iter 5000: loss 0.470.\n",
      "Iter 6000: loss 0.466.\n",
      "Iter 7000: loss 0.461.\n",
      "\n",
      "\n",
      "Currently at stage 6. Reinforce: True\n",
      "Iter 1000: loss 0.766.\n",
      "Iter 2000: loss 0.751.\n",
      "Iter 3000: loss 0.735.\n",
      "Iter 4000: loss 0.734.\n",
      "Iter 5000: loss 0.724.\n",
      "Iter 6000: loss 0.710.\n",
      "Iter 7000: loss 0.706.\n",
      "Iter 8000: loss 0.702.\n",
      "Iter 9000: loss 0.693.\n",
      "Iter 10000: loss 0.690.\n",
      "Iter 11000: loss 0.693.\n",
      "\n",
      "\n",
      "Currently at stage 7. Reinforce: True\n",
      "Iter 1000: loss 0.861.\n",
      "Iter 2000: loss 0.837.\n",
      "Iter 3000: loss 0.825.\n",
      "Iter 4000: loss 0.817.\n",
      "Iter 5000: loss 0.815.\n",
      "Iter 6000: loss 0.806.\n",
      "Iter 7000: loss 0.798.\n",
      "Iter 8000: loss 0.791.\n",
      "Iter 9000: loss 0.788.\n",
      "Iter 10000: loss 0.788.\n",
      "Iter 11000: loss 0.776.\n",
      "Iter 12000: loss 0.781.\n",
      "Iter 13000: loss 0.777.\n",
      "Iter 14000: loss 0.768.\n",
      "Iter 15000: loss 0.775.\n",
      "Iter 16000: loss 0.774.\n",
      "Iter 17000: loss 0.765.\n",
      "\n",
      "\n",
      "Currently at stage 8. Reinforce: True\n",
      "Iter 1000: loss 0.902.\n",
      "Iter 2000: loss 0.899.\n",
      "Iter 3000: loss 0.892.\n",
      "Iter 4000: loss 0.887.\n",
      "Iter 5000: loss 0.885.\n",
      "Iter 6000: loss 0.878.\n",
      "Iter 7000: loss 0.875.\n",
      "Iter 8000: loss 0.877.\n",
      "Iter 9000: loss 0.872.\n",
      "Iter 10000: loss 0.872.\n",
      "Iter 11000: loss 0.873.\n",
      "Iter 12000: loss 0.861.\n",
      "Iter 13000: loss 0.879.\n",
      "Iter 14000: loss 0.864.\n",
      "Iter 15000: loss 0.864.\n",
      "Iter 16000: loss 0.867.\n",
      "Iter 17000: loss 0.856.\n",
      "Iter 18000: loss 0.865.\n",
      "Iter 19000: loss 0.859.\n",
      "Iter 20000: loss 0.860.\n",
      "Iter 21000: loss 0.857.\n",
      "Iter 22000: loss 0.850.\n",
      "Iter 23000: loss 0.860.\n",
      "Iter 24000: loss 0.851.\n",
      "Iter 25000: loss 0.860.\n",
      "\n",
      "\n",
      "Currently at stage 9. Reinforce: True\n",
      "Iter 1000: loss 0.971.\n",
      "Iter 2000: loss 0.955.\n",
      "Iter 3000: loss 0.954.\n",
      "Iter 4000: loss 0.949.\n",
      "Iter 5000: loss 0.945.\n",
      "Iter 6000: loss 0.938.\n",
      "Iter 7000: loss 0.943.\n",
      "Iter 8000: loss 0.942.\n",
      "Iter 9000: loss 0.929.\n",
      "Iter 10000: loss 0.919.\n",
      "Iter 11000: loss 0.927.\n",
      "Iter 12000: loss 0.929.\n",
      "Iter 13000: loss 0.928.\n",
      "Iter 14000: loss 0.922.\n",
      "Iter 15000: loss 0.921.\n",
      "Iter 16000: loss 0.919.\n",
      "Iter 17000: loss 0.921.\n",
      "Iter 18000: loss 0.918.\n",
      "Iter 19000: loss 0.919.\n",
      "Iter 20000: loss 0.912.\n",
      "Iter 21000: loss 0.927.\n",
      "Iter 22000: loss 0.912.\n",
      "Iter 23000: loss 0.914.\n",
      "Iter 24000: loss 0.909.\n",
      "Iter 25000: loss 0.912.\n",
      "Iter 26000: loss 0.914.\n",
      "Iter 27000: loss 0.906.\n",
      "Iter 28000: loss 0.902.\n",
      "Iter 29000: loss 0.914.\n",
      "Iter 30000: loss 0.901.\n",
      "Iter 31000: loss 0.913.\n",
      "Iter 32000: loss 0.907.\n",
      "Iter 33000: loss 0.899.\n",
      "Iter 34000: loss 0.903.\n",
      "Iter 35000: loss 0.900.\n",
      "Iter 36000: loss 0.896.\n",
      "Iter 37000: loss 0.908.\n",
      "Iter 38000: loss 0.908.\n",
      "\n",
      "Done OCF training.\n",
      "Training takes 0.115 hours\n"
     ]
    }
   ],
   "source": [
    "# Molecule first order.\n",
    "env_name = 'molecule'\n",
    "c = 1.5\n",
    "num_optimize_iters = [int(1000 * (c**i)) for i in range(10)]\n",
    "train_helper(env_name, num_optimize_iters, warm_up_threshold=5, zero_order=False, save_interval=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afb0fcc",
   "metadata": {},
   "source": [
    "**VISUALIZATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6600346a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tests import visualize\n",
    "from utils import get_environment\n",
    "import importlib\n",
    "import benchmarks.sb3_utils\n",
    "importlib.reload(benchmarks.sb3_utils)\n",
    "from benchmarks.sb3_utils import setup_benchmark_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b3b041da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "core.scoring.ScoreFunctionFactory: SCOREFUNCTION: ref2015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Observation spaces do not match: Box([-180. -180. -180. -180. -180. -180. -180. -180. -180. -180. -180. -180.\n -180. -180. -180. -180.], [180. 180. 180. 180. 180. 180. 180. 180. 180. 180. 180. 180. 180. 180.\n 180. 180.], (16,), float32) != Box(-180.0, 180.0, (16,), float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[89], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m env \u001b[38;5;241m=\u001b[39m get_environment(env_name)\n\u001b[1;32m      4\u001b[0m method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSAC\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 5\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43msetup_benchmark_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_0_99\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m visualize(env, model, num_step\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, benchmark_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      7\u001b[0m               extra_args\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom\u001b[39m\u001b[38;5;124m'\u001b[39m, img_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/mnt/c/Users/DELL/dpo/benchmarks/sb3_utils.py:97\u001b[0m, in \u001b[0;36msetup_benchmark_model\u001b[0;34m(method, env, env_name, model_version)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msetup_benchmark_model\u001b[39m(method, env, env_name, model_version\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     96\u001b[0m     model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m env_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m method \u001b[38;5;241m+\u001b[39m model_version\n\u001b[0;32m---> 97\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43m_load_benchmark_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m     model\u001b[38;5;241m.\u001b[39mset_env(env)\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m/mnt/c/Users/DELL/dpo/benchmarks/sb3_utils.py:92\u001b[0m, in \u001b[0;36m_load_benchmark_model\u001b[0;34m(method, model_path, env)\u001b[0m\n\u001b[1;32m     90\u001b[0m     model \u001b[38;5;241m=\u001b[39m PPO\u001b[38;5;241m.\u001b[39mload(model_path, env\u001b[38;5;241m=\u001b[39menv)\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSAC\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 92\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mSAC\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/pyro-env-py39/lib/python3.9/site-packages/stable_baselines3/common/base_class.py:693\u001b[0m, in \u001b[0;36mBaseAlgorithm.load\u001b[0;34m(cls, path, env, device, custom_objects, print_system_info, force_reset, **kwargs)\u001b[0m\n\u001b[1;32m    691\u001b[0m env \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_env(env, data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mverbose\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    692\u001b[0m \u001b[38;5;66;03m# Check if given env is valid\u001b[39;00m\n\u001b[0;32m--> 693\u001b[0m \u001b[43mcheck_for_correct_spaces\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mobservation_space\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maction_space\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[38;5;66;03m# Discard `_last_obs`, this will force the env to reset before training\u001b[39;00m\n\u001b[1;32m    695\u001b[0m \u001b[38;5;66;03m# See issue https://github.com/DLR-RM/stable-baselines3/issues/597\u001b[39;00m\n\u001b[1;32m    696\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_reset \u001b[38;5;129;01mand\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/pyro-env-py39/lib/python3.9/site-packages/stable_baselines3/common/utils.py:228\u001b[0m, in \u001b[0;36mcheck_for_correct_spaces\u001b[0;34m(env, observation_space, action_space)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;124;03mChecks that the environment has same spaces as provided ones. Used by BaseAlgorithm to check if\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;124;03mspaces match after loading the model with given env.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;124;03m:param action_space: Action space to check against\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m observation_space \u001b[38;5;241m!=\u001b[39m env\u001b[38;5;241m.\u001b[39mobservation_space:\n\u001b[0;32m--> 228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mObservation spaces do not match: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobservation_space\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m != \u001b[39m\u001b[38;5;132;01m{\u001b[39;00menv\u001b[38;5;241m.\u001b[39mobservation_space\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m action_space \u001b[38;5;241m!=\u001b[39m env\u001b[38;5;241m.\u001b[39maction_space:\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAction spaces do not match: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maction_space\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m != \u001b[39m\u001b[38;5;132;01m{\u001b[39;00menv\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Observation spaces do not match: Box([-180. -180. -180. -180. -180. -180. -180. -180. -180. -180. -180. -180.\n -180. -180. -180. -180.], [180. 180. 180. 180. 180. 180. 180. 180. 180. 180. 180. 180. 180. 180.\n 180. 180.], (16,), float32) != Box(-180.0, 180.0, (16,), float32)"
     ]
    }
   ],
   "source": [
    "# Visualization from benchmark\n",
    "env_name = 'molecule'\n",
    "env = get_environment(env_name)\n",
    "method='SAC'\n",
    "model = setup_benchmark_model(method, env, env_name, model_version='_0_99')\n",
    "visualize(env, model, num_step=100, benchmark_model=True,\n",
    "              extra_args='random', img_path=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a76f7ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyro-env-py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
